{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from sklearn import decomposition, ensemble\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#import xgboost\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(['punkt', 'stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop(sent, stop_word_list):\n",
    "    return [term for term in sent if term not in stop_word_list]\n",
    "\n",
    "porter = PorterStemmer()\n",
    "def stem_tokens(token_list):\n",
    "    token_stem = [porter.stem(term) for term in token_list]\n",
    "    return(token_stem)\n",
    "\n",
    "def get_clean_text(txt):\n",
    "    txt = [txt]\n",
    "    feed_token = [word_tokenize(sent.lower()) for sent in txt]\n",
    "    \n",
    "    stop_punct = list(punctuation)\n",
    "    stop_nltk = stopwords.words(\"english\")\n",
    "    stop_updated = stop_nltk + stop_punct\n",
    "    \n",
    "    feed_token_clean = [del_stop(sent, stop_updated) for sent in feed_token]\n",
    "    feed_token_stemmed = [stem_tokens(tk) for tk in feed_token_clean]\n",
    "    \n",
    "    clean_text = [\" \".join(sent) for sent in feed_token_clean]\n",
    "    return(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model & Feature Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_objects_func():\n",
    "    #Load the TFIDF Vectoriser\n",
    "    with open(os.getcwd() + '/Model_Output/feature_transformer.pkl', 'rb') as f:\n",
    "        tfidf_vect = pickle.load(f)\n",
    "    \n",
    "    #Load the pre-trained model\n",
    "    with open(os.getcwd() + '/Model_Output/model_file.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    #Load Encoder mappings used in the model to get the name of the primary hastags\n",
    "    enc_mapping = pd.read_csv(os.getcwd() + '/Model_Output/encoder_mapping.csv')\n",
    "    enc_mapping = enc_mapping.sort_values(['hashtag_encoding'])\n",
    "    \n",
    "    return(tfidf_vect, model, enc_mapping)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hashtag_prediction(input_text, topN):\n",
    "    input_text = [input_text]\n",
    "    \n",
    "    #Load the tfidf vectorizer, model and encoder mappings\n",
    "    tfidf_vectorizer, classifier, encoder_mapping = load_objects_func()\n",
    "    \n",
    "    #Clean the text\n",
    "    clean_text = get_clean_text(input_text)\n",
    "    \n",
    "    #Generate Features for scoring\n",
    "    feature_vector = tfidf_vectorizer.transform(clean_text)\n",
    "    \n",
    "    #Generate Predictions\n",
    "    prob_predictions = classifier.predict(feature_vector)\n",
    "    \n",
    "    prediction_df = encoder_mapping.copy()\n",
    "    prediction_df = prediction_df.sort_values(['hashtag_encoding'])\n",
    "    prediction_df['probability'] = prob_predictions.tolist()[0]\n",
    "    prediction_df = prediction_df.sort_values(['probability'], ascending=False)\n",
    "    topN_hashtag = prediction_df[0:topN]['hashtag'].to_list()\n",
    "    return(topN_hashtag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['starting-out', 'career-growth', 'career-switch']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'Hello. I am Yashi. I have just started freelancing as a digital marketer. I want to know how to get my freelance digital marketing business off the ground even when I have zero experience?'\n",
    "\n",
    "get_hashtag_prediction(input_txt, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['career-growth', 'starting-out', 'networking']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'Hello. I am XYZ. i am looking for freelancing jobs in the field of analytics'\n",
    "\n",
    "get_hashtag_prediction(input_txt, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['starting-out', 'speaking-out', 'networking']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'Hi everyone I am Abhilasha like most of us my mother is also my inspiration.I always wanted to do something for her give her the recognisation that she deserves and also to every other homemakers like her so I came across an idea of creating an online platform for the showcase of every things that they make(not just food)and started telling the world about them.I run my page in instagram but I have little help from the people I know. I lack in networking.I do not want to stop my work and in need to more stories. Can you please show me some way that how I should attract people to tell their stories to the world  how I may convince my friends to share their mothers tales or my followers'\n",
    "\n",
    "get_hashtag_prediction(input_txt, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['networking', 'career-growth', 'starting-out']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'Hi , Hope everyone is safe, healthy and having a great weekend. I am a second-year MBA student and the past few months have been very transformational for me on a professional and personal level. I am looking to collaborate on exciting new projects and ideas. To give you an overview of my skills I am attaching my LinkedIn profile (https://www.linkedin.com/in/tanya-r-dwivedii/). My fields of interest are marketing and data analytics. Cheers! #networking #marketing #data analytics #productdesign'\n",
    "\n",
    "get_hashtag_prediction(input_txt, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inspiration', 'selfcare', 'speaking-out']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_txt = 'How depressing is depression ?  I sit watching the clock tick  Anxious its reaching the sun  Nervous it doesnt stop  The pale blue now a taboo  As I wish I slept through the depths  Not knowing the blue. Life as a boat had me stowing on it  The tides hitting the sides  And the waters downcasting my eyes  The sailors pricking my skin  Akin my abused core  My head bowling against the wind  Flowing Tears of contempt, result of the force . The voice box scarred from the screams  Locked with chains of grief  Never reefed a ripple in the sea, Could never reef a ripple in the sea... The steady warm currents of the deep  Promising the bracing  As tempting and rushing  For a refugee of yesterday. The shaken Impulse Met the reflecting bed And now The corals chattered her ignored fretting waves.'\n",
    "\n",
    "get_hashtag_prediction(input_txt, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
